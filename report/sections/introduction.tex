

The objective of this project is to simulate and evaluate reinforcement learning algorithms that enable autonomous vehicles to perform complex driving tasks,
such as merging, lane changing, and overtaking, while ensuring safety and optimizing traffic flow.

Specifically, the project will focus on \textbf{simulating scenarios at road intersections where multiple autonomous vehicles must determine the order of crossing
and appropriate speeds, aiming to maximize traffic efficiency and minimize collision risks.}

This will be achieved using an agent-based simulation framework - \textbf{\textit{Highway Env}}\cite{highwayenv} - where a group of four agents, each trained with different Deep Reinforcement Learning (DRL) policies, will face dynamic environmental changes. The agents will
be tested under various combinations of environmental variables (e.g., traffic density,vehicle speed) to evaluate their behavior and decision-making processes in real-time. 

This experimental setup will create a Multi-Agent System (MAS) within a dynamic environment, concentrating on decision-making strategies for autonomous driving.

Through this project, we aim to address critical questions regarding the scalability and robustness of DRL models in autonomous driving. 

In particular, the research will explore how well these algorithms generalize to unseen environments â€” a key challenge for deep learning-based approaches. 

The insights gained can inform the real-world applicability of DRL for autonomous vehicles, especially in unpredictable or changing environments.

This work is structured into several chapters, each addressing a distinct aspect of the research. 

The \textit{Literature Review} explores related studies, offering a critical analysis of existing work to position the research within the broader field. 

Next, the \textit{Problem Formalization} chapter defines the problem, introduces decision support models, and describes the agent-based simulation 
framework. 
This chapter also elaborates on the training algorithms and policies tested, the frameworks used for policy evaluation, 
and the global key performance indicators (KPIs) employed to measure system performance.

The \textit{Methodology} chapter details the research approach, focusing on training agents through reinforcement learning and implementing practical 
training configurations. 
It also discusses the introduction of system perturbations to evaluate robustness and scalability, including metrics description and data collection 
methods.

In the \textit{Results and Discussion} chapter, the study presents and interprets the findings, analyzing metrics such as episode length, average speed, 
and collision rates. The performance of various algorithms and policies is classified and compared.

Finally, the \textit{Conclusions and Future Work} chapter summarizes the study's main outcomes and suggests directions for future research, 
emphasizing areas for improvement and potential expansions of the work.
