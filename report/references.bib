@misc{highwayenv,
  author       = {Farama Foundation},
  title        = {HighwayEnv: A minimalist environment for decision-making in autonomous driving},
  howpublished = {\url{https://github.com/Farama-Foundation/HighwayEnv}},
  year         = {2025},
  note         = {Accessed: 2025-01-02}
}

@article{mnih2015dqn,
  author    = {Mnih, Volodymyr and Kavukcuoglu, Koray and Silver, David and Rusu, Andrei A. and Veness, Joel and Bellemare, Marc G. and Graves, Alex and Riedmiller, Martin and Fidjeland, Andreas K. and Ostrovski, Georg and Petersen, Stig and Beattie, Charles and Sadik, Amir and Antonoglou, Ioannis and King, Helen and Kumaran, Dharshan and Wierstra, Daan and Legg, Shane and Hassabis, Demis},
  title     = {Human-level control through deep reinforcement learning},
  journal   = {Nature},
  volume    = {518},
  pages     = {529--533},
  year      = {2015},
  publisher = {Nature Publishing Group}
}

@inproceedings{schulman2017attention,
  author    = {Schulman, John and Wolski, Filip and Dhariwal, Prafulla and Radford, Alec and Klimov, Oleg},
  title     = {Proximal Policy Optimization Algorithms},
  booktitle = {Proceedings of the International Conference on Machine Learning (ICML)},
  year      = {2017}
}

@article{vaswani2017attention,
  author    = {Vaswani, Ashish and Shazeer, Noam and Parmar, Niki and Uszkoreit, Jakob and Jones, Llion and Gomez, Aidan N. and Kaiser, Łukasz and Polosukhin, Illia},
  title     = {Attention is All You Need},
  journal   = {Advances in Neural Information Processing Systems (NeurIPS)},
  volume    = {30},
  year      = {2017}
}

@inproceedings{lecun1998cnn,
  author    = {LeCun, Yann and Bottou, Léon and Bengio, Yoshua and Haffner, Patrick},
  title     = {Gradient-based learning applied to document recognition},
  booktitle = {Proceedings of the IEEE},
  volume    = {86},
  number    = {11},
  pages     = {2278--2324},
  year      = {1998}
}

@inproceedings{schulman2017ppo,
  author    = {John Schulman and Philipp Moritz and Sergey Levine and Michael I. Jordan and Pieter Abbeel},
  title     = {Proximal Policy Optimization Algorithms},
  booktitle = {Proceedings of the 34th International Conference on Machine Learning (ICML)},
  year      = {2017},
  pages     = {3371--3380},
  url       = {http://proceedings.mlr.press/v70/schulman17a.html}
}

@book{sutton2018reinforcement,
  title={Reinforcement Learning: An Introduction},
  author={Sutton, Richard S and Barto, Andrew G},
  year={2018},
  publisher={MIT Press},
  edition={2nd}
}

@inproceedings{jiang2018learning,
  title={Learning attentional communication for multi-agent cooperation},
  author={Jiang, Jiechuan and Lu, Zongqing},
  booktitle={Advances in Neural Information Processing Systems (NeurIPS)},
  year={2018},
  url={https://arxiv.org/abs/1805.07733}
}


@software{stable-baselines3,
  author       = {Raffin, Antonin and Hill, Ashley and Gleave, Adam and Kanervisto, Anssi and Ernestus, Maximilian and Dormann, Noah},
  title        = {Stable-Baselines3: Reliable Reinforcement Learning Implementations},
  year         = 2021,
  publisher    = {GitHub},
  url          = {https://github.com/DLR-RM/stable-baselines3},
  version      = {1.6.0},
  note         = {Accessed: 2025-01-02}
}

@article{DBLP,
  author       = {Edouard Leurent and
                  Jean Mercat},
  title        = {Social Attention for Autonomous Decision-Making in Dense Traffic},
  journal      = {CoRR},
  volume       = {abs/1911.12250},
  year         = {2019},
  url          = {http://arxiv.org/abs/1911.12250},
  eprinttype    = {arXiv},
  eprint       = {1911.12250},
  timestamp    = {Tue, 03 Dec 2019 20:41:07 +0100},
  biburl       = {https://dblp.org/rec/journals/corr/abs-1911-12250.bib},
  bibsource    = {dblp computer science bibliography, https://dblp.org}
}


@misc{rl-agents,
  author = {Leurent, Edouard},
  title = {rl-agents: Implementations of Reinforcement Learning algorithms},
  year = {2018},
  publisher = {GitHub},
  journal = {GitHub repository},
  howpublished = {\url{https://github.com/eleurent/rl-agents}},
}

@misc{pytorch_rl_tutorial,
  author = {Adam Paszke},
  title = {Reinforcement Learning (Q-Learning) Tutorial},
  year = {n.d.},
  url = {https://pytorch.org/tutorials/intermediate/reinforcement_q_learning.html},
  note = {Accessed: 2024-12-15}
}

@inproceedings{jaques2019social,
  title={Social influence as intrinsic motivation for multi-agent deep reinforcement learning},
  author={Jaques, Natasha and Lazaridou, Angeliki and Hughes, Edward and Gulcehre, Caglar and Ortega, Pedro and Strouse, DJ and Leibo, Joel Z and De Freitas, Nando},
  booktitle={International conference on machine learning},
  pages={3040--3049},
  year={2019},
  organization={PMLR}
}
