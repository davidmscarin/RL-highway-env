@misc{highwayenv,
  author       = {Farama Foundation},
  title        = {HighwayEnv: A minimalist environment for decision-making in autonomous driving},
  howpublished = {\url{https://github.com/Farama-Foundation/HighwayEnv}},
  year         = {2025},
  note         = {Accessed: 2025-01-02}
}

@article{mnih2015dqn,
  author    = {Mnih, Volodymyr and Kavukcuoglu, Koray and Silver, David and Rusu, Andrei A. and Veness, Joel and Bellemare, Marc G. and Graves, Alex and Riedmiller, Martin and Fidjeland, Andreas K. and Ostrovski, Georg and Petersen, Stig and Beattie, Charles and Sadik, Amir and Antonoglou, Ioannis and King, Helen and Kumaran, Dharshan and Wierstra, Daan and Legg, Shane and Hassabis, Demis},
  title     = {Human-level control through deep reinforcement learning},
  journal   = {Nature},
  volume    = {518},
  pages     = {529--533},
  year      = {2015},
  publisher = {Nature Publishing Group}
}

@inproceedings{schulman2017attention,
  author    = {Schulman, John and Wolski, Filip and Dhariwal, Prafulla and Radford, Alec and Klimov, Oleg},
  title     = {Proximal Policy Optimization Algorithms},
  booktitle = {Proceedings of the International Conference on Machine Learning (ICML)},
  year      = {2017}
}

@article{vaswani2017attention,
  author    = {Vaswani, Ashish and Shazeer, Noam and Parmar, Niki and Uszkoreit, Jakob and Jones, Llion and Gomez, Aidan N. and Kaiser, Łukasz and Polosukhin, Illia},
  title     = {Attention is All You Need},
  journal   = {Advances in Neural Information Processing Systems (NeurIPS)},
  volume    = {30},
  year      = {2017}
}

@inproceedings{lecun1998cnn,
  author    = {LeCun, Yann and Bottou, Léon and Bengio, Yoshua and Haffner, Patrick},
  title     = {Gradient-based learning applied to document recognition},
  booktitle = {Proceedings of the IEEE},
  volume    = {86},
  number    = {11},
  pages     = {2278--2324},
  year      = {1998}
}

@inproceedings{schulman2017ppo,
  author    = {John Schulman and Philipp Moritz and Sergey Levine and Michael I. Jordan and Pieter Abbeel},
  title     = {Proximal Policy Optimization Algorithms},
  booktitle = {Proceedings of the 34th International Conference on Machine Learning (ICML)},
  year      = {2017},
  pages     = {3371--3380},
  url       = {http://proceedings.mlr.press/v70/schulman17a.html}
}

@book{sutton2018reinforcement,
  title={Reinforcement Learning: An Introduction},
  author={Sutton, Richard S and Barto, Andrew G},
  year={2018},
  publisher={MIT Press},
  edition={2nd}
}

@inproceedings{jiang2018learning,
  title={Learning attentional communication for multi-agent cooperation},
  author={Jiang, Jiechuan and Lu, Zongqing},
  booktitle={Advances in Neural Information Processing Systems (NeurIPS)},
  year={2018},
  url={https://arxiv.org/abs/1805.07733}
}


@software{stable-baselines3,
  author       = {Raffin, Antonin and Hill, Ashley and Gleave, Adam and Kanervisto, Anssi and Ernestus, Maximilian and Dormann, Noah},
  title        = {Stable-Baselines3: Reliable Reinforcement Learning Implementations},
  year         = 2021,
  publisher    = {GitHub},
  url          = {https://github.com/DLR-RM/stable-baselines3},
  version      = {1.6.0},
  note         = {Accessed: 2025-01-02}
}

@misc{rl-agents,
  author = {Leurent, Edouard},
  title = {rl-agents: Implementations of Reinforcement Learning algorithms},
  year = {2018},
  publisher = {GitHub},
  journal = {GitHub repository},
  howpublished = {\url{https://github.com/eleurent/rl-agents}},
}

@article{leurent2019socialattention,
  author = {Leurent, Edouard and Mercat, Jean},
  title = {Social Attention for Autonomous Decision-Making in Dense Traffic},
  journal = {arXiv preprint arXiv:1903.12220},
  year = {2019}
}

@misc{highwaymultiagentenv,
  author = {Chen, Baiming},
  title = {highway\_multiagent\_env},
  year = {2020},
  publisher = {GitHub},
  journal = {GitHub repository},
  howpublished = {\url{https://github.com/baimingc/highway_multiagent_env}},
}

@inproceedings{wei2019intellilight,
  author = {Wei, H. and Zheng, G. and Yao, H. and Li, Z.},
  title = {IntelliLight: A Reinforcement Learning Approach for Intelligent Traffic Light Control},
  booktitle = {Proceedings of the 25th ACM SIGKDD International Conference on Knowledge Discovery and Data Mining},
  year = {2019},
  pages = {2496--2505}
}

@inproceedings{yang2018meanfield,
  author = {Yang, Y. and Luo, R. and Li, M. and Zhou, M. and Zhang, W. and Wang, J.},
  title = {Mean Field Multi-Agent Reinforcement Learning},
  booktitle = {Proceedings of the International Conference on Machine Learning (ICML)},
  year = {2018}
}

@article{chu2019multiagent,
  author = {Chu, T. and Wang, J. and Codeca, L. and Li, Z.},
  title = {Multi-Agent Deep Reinforcement Learning for Large-Scale Traffic Signal Control},
  journal = {IEEE Transactions on Intelligent Transportation Systems},
  year = {2019},
  volume = {21},
  number = {3},
  pages = {1086--1095}
}

@article{kiran2021survey,
  author = {Kiran, B. R. and Sobh, I. and Talpaert, V. and Mannion, P. and Al Sallab, A. A. and Yogamani, S. and P\'erez, P.},
  title = {Deep Reinforcement Learning for Autonomous Driving: A Survey},
  journal = {IEEE Transactions on Intelligent Transportation Systems},
  year = {2021},
  volume = {23},
  number = {2},
  pages = {490--507}
}

@article{chen2021collisionavoidance,
  author = {Chen, C. and Wang, J. and Jiang, C. and Ding, W. and Xie, J.},
  title = {Autonomous Vehicle Collision Avoidance Using Multi-Agent Reinforcement Learning},
  journal = {Applied Sciences},
  year = {2021},
  volume = {11},
  number = {5},
  pages = {2241}
}

@inproceedings{wang2020multiintersection,
  author = {Wang, Y. and Ma, H. and Yang, J.},
  title = {Multi-Agent Reinforcement Learning for Multi-Intersection Traffic Signal Control},
  booktitle = {Proceedings of the AAAI Conference on Artificial Intelligence},
  year = {2020},
  volume = {34},
  number = {04},
  pages = {10429--10436}
}

@article{baker2020emergent,
  author = {Baker, B. and Kanitscheider, I. and Markov, T. and Wu, Y. and Powell, R. and McGrew, B. and Mordatch, I.},
  title = {Emergent Behaviors in Multi-Agent Games Through Multi-Agent Reinforcement Learning},
  journal = {arXiv preprint arXiv:2003.08839},
  year = {2020}
}

@article{thananjeyan2021,
  author = {Thananjeyan, B. and et al.},
  title = {Safety Augmented Value Estimation for Efficient Safe Reinforcement Learning},
  journal = {arXiv preprint arXiv:2105.13850},
  year = {2021}
}

@article{DBLP,
  author       = {Edouard Leurent and
                  Jean Mercat},
  title        = {Social Attention for Autonomous Decision-Making in Dense Traffic},
  journal      = {CoRR},
  volume       = {abs/1911.12250},
  year         = {2019},
  url          = {http://arxiv.org/abs/1911.12250},
  eprinttype    = {arXiv},
  eprint       = {1911.12250},
  timestamp    = {Tue, 03 Dec 2019 20:41:07 +0100},
  biburl       = {https://dblp.org/rec/journals/corr/abs-1911-12250.bib},
  bibsource    = {dblp computer science bibliography, https://dblp.org}
}

@misc{pytorchrltutorial,
  author = {Adam Paszke},
  title = {Reinforcement Learning (Q-Learning) Tutorial},
  year = {n.d.},
  url = {https://pytorch.org/tutorials/intermediate/reinforcement_q_learning.html},
  note = {Accessed: 2024-12-15}
}

@inproceedings{jaques2019social,
  title={Social influence as intrinsic motivation for multi-agent deep reinforcement learning},
  author={Jaques, Natasha and Lazaridou, Angeliki and Hughes, Edward and Gulcehre, Caglar and Ortega, Pedro and Strouse, DJ and Leibo, Joel Z and De Freitas, Nando},
  booktitle={International conference on machine learning},
  pages={3040--3049},
  year={2019},
  organization={PMLR}
}
